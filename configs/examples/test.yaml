# ======================================================== #
# Example Configuration file for the training of the model #
# ======================================================== #

# #mode: 'train'
# mode: 'evaluate'

# Name of the model to use and the input dimension
model:
  #name: 'ResidualComplexNN'
  name: 'ResidualComplexNNwithattention'
  #name: 'ResidualComplexNNwith_MH_attention'
  input_dim: 6 # number of features

# Path to the data
data:
  #signal_path: /scratch4/levans/tth-network/Datasets/full/01_03_24/ttH/ttH_PP8_allYears.h5
  signal_path: /scratch4/levans/tth-network/Datasets/test/ttH_tester_file.h5
  #background_path: /scratch4/levans/tth-network/Datasets/full/01_03_24/ttbb/ttbb_PP8_allYears.h5
  background_path: /scratch4/levans/tth-network/Datasets/test/ttbb_tester_file.h5
  plot_inputs: False

Network_type:
  - FFNN

# Example features to be used for training the model

features:
  - jet_pt_1
  - jet_pt_2
  - jet_pt_3
  - jet_pt_4
  - dRbb_avg_Sort4
  - HT_all
  # - HT_all
  # - H0_all
  # - H1_all
  # - H2_jets
  # - dRbb_avg_Sort4
  # - dRlj_MindR
  # - dEtajj_MaxdEta
  # - dRlepbb_MindR_70
  # - L2_Reco_higgs_pt
  # - L2_Reco_higgs_m
  # - nJets
  # - Aplanarity_jets
  # - Centrality_all
  # - met_met

# add safety guard for duplicate features! :D

# Preparation: Coming soon!
# -

# Hyperparameters for training the model
training:
  num_epochs: 100           # number of epochs to train the model, which are the number of times the model sees the entire training dataset
  learning_rate: 0.00001   # learning rate for the optimiser, which is a technique to update the weights
  weight_decay: 0.001       # L2 regularization, which is a technique to reduce overfitting
  batch_size: 100            # batch size for training, which is the number of samples per gradient update
  patience: 10               # epochs before early stopping/learning rate decay
  early_stopping: True      # early stopping if validation loss does not improve
  use_scheduler: False       # learning rate decay if validation loss does not improve
  factor: 0.5               # factor by which the learning rate will be reduced, if use_scheduler is True
  initialise_weights: True  # initialise weights of the model
  balance_classes: True     # use class weights to balance the dataset
  criterion: 'BCELoss'      # loss function to use
  use_cosine_burnin: True          # use burnin for the learning rate scheduler
  #save_model: False
  #model_save_path: 'models/'
  #save_frequency: 1
  #save_plots: False

evaluation:
  use_saved_model: False
  saved_model_path: /scratch4/levans/tth-network/models/outputs/model.pt

  # add check-points (use pickle files and save model after each epoch) etc.