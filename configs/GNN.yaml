# ======================= #
# GNN1 Configuration file #
# ======================= #


# Name of the model to use and the input dimension
model:
  name: 'ResidualGNN1'
  input_dim: 2 # number of features

# Path to the data
data:
  signal_path: Datasets/signal_GNN.h5
  background_path: Datasets/background_GNN.h5
  pre_training_path: Datasets/graphsets/

Network_type:
  - GNN

features:
  node_features:
    - jet_pt_1
    - jet_pt_2
    - jet_pt_3
    - jet_pt_4
    - jet_pt_5
    - jet_pt_6
    - jet_pt_7
    - jet_pt_8
    - jet_pt_9
    - jet_pt_10
    - jet_eta_1
    - jet_eta_2
    - jet_eta_3
    - jet_eta_4
    - jet_eta_5
    - jet_eta_6
    - jet_eta_7
    - jet_eta_8
    - jet_eta_9
    - jet_eta_10
    - jet_phi_1
    - jet_phi_2
    - jet_phi_3
    - jet_phi_4
    - jet_phi_5
    - jet_phi_6
    - jet_phi_7
    - jet_phi_8
    - jet_phi_9
    - jet_phi_10
    
  edge_features: # add dEta and dPhi
    - dRbb_avg_Sort4
  global_features:
    - HT_all

# Preparation: Coming soon!

# Hyperparameters for training the model
training:
  num_epochs: 10            # number of epochs to train the model, which are the number of times the model sees the entire training dataset
  learning_rate: 0.00001    # learning rate for the optimizer, which is a technique to update the weights
  weight_decay: 0.01        # L2 regularization, which is a technique to reduce overfitting
  batch_size: 32            # batch size for training, which is the number of samples per gradient update
  patience: 2               # epochs before early stopping/learning rate decay
  early_stopping: True      # early stopping if validation loss does not improve
  use_scheduler: True       # learning rate decay if validation loss does not improve
  factor: 0.1               # factor by which the learning rate will be reduced, if use_scheduler is True
  initialise_weights: True  # initialise weights of the model
  balance_classes: False     # use class weights to balance the dataset
  criterion: 'BCELoss'      # loss function to use
