# ======================================================== #
# Example Configuration file for the training of the model #
# ======================================================== #


# Name of the model to use and the input dimension
model:
  name: 'ResidualComplexNN'
  #name: 'LorentzInteractionNetwork'
  input_dim: 16 # number of features
  #hidden_dim: 16 # hidden dimension
  #output_dim: 2  # output dimension

# Path to the data
data:
  signal_path: Datasets/signal2.h5
  background_path: Datasets/ttbarbackground2.h5

# Example features to be used for training the model

features:
  - HT_all
  - HT_jets
  - H0_all
  - dRbb_HiggsMass_70
  - dRbb_avg_70
  - dRbb_avg_Sort4
  - met_phi
  - met_met
  - nJets
  - Aplanarity_jets
  - Centrality_all
  - dRlj_MindR
  - mu_pt
  - mu_eta
  - mu_phi
  - mu_e

# Preparation: Coming soon!
# -

# Hyperparameters for training the model
training:
  num_epochs: 10             # number of epochs to train the model, which are the number of times the model sees the entire training dataset
  learning_rate: 0.00001        #0.0001    # learning rate for the optimizer, which is a technique to update the weights
  weight_decay: 0.01       # L2 regularization, which is a technique to reduce overfitting
  batch_size: 32         # batch size for training, which is the number of samples per gradient update
  patience: 2               # epochs before early stopping/learning rate decay
  early_stopping: True      # early stopping if validation loss does not improve
  use_scheduler: True       # learning rate decay if validation loss does not improve
  factor: 0.1               # factor by which the learning rate will be reduced, if use_scheduler is True
  initialise_weights: True  # initialise weights of the model
  balance_classes: True     # use class weights to balance the dataset
  #save_model: False
  #model_save_path: 'models/'
  #save_frequency: 1

