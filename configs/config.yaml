# ======================================================== #
# Example Configuration file for the training of the model #
# ======================================================== #


# Name of the model to use and the input dimension
model:
  #name: 'ResidualComplexNN'
  name: 'ResidualComplexNNwithattention'
  input_dim: 9 # number of features

# Path to the data
data:
  signal_path: Datasets/signal2.h5
  background_path: Datasets/ttbarbackground2.h5

Network_type:
  - FFNN

# Example features to be used for training the model

features:
  - HT_all
  - H0_all
  - dRbb_HiggsMass_70
  - dRbb_avg_70
  - dRbb_avg_Sort4
  - nJets
  - Aplanarity_jets
  - Centrality_all
  - dRlj_MindR

# Preparation: Coming soon!
# -

# Hyperparameters for training the model
training:
  num_epochs: 20            # number of epochs to train the model, which are the number of times the model sees the entire training dataset
  learning_rate: 0.000001   # learning rate for the optimiser, which is a technique to update the weights
  weight_decay: 0.001       # L2 regularization, which is a technique to reduce overfitting
  batch_size: 32            # batch size for training, which is the number of samples per gradient update
  patience: 6               # epochs before early stopping/learning rate decay
  early_stopping: True      # early stopping if validation loss does not improve
  use_scheduler: True       # learning rate decay if validation loss does not improve
  factor: 0.5               # factor by which the learning rate will be reduced, if use_scheduler is True
  initialise_weights: True  # initialise weights of the model
  balance_classes: True     # use class weights to balance the dataset
  criterion: 'BCELoss'      # loss function to use
  #save_model: False
  #model_save_path: 'models/'
  #save_frequency: 1
  #save_plots: False
  #

  # add check-points (use pickle files and save model after each epoch) etc.